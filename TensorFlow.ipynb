{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of TensorFlow.ipynb","version":"0.3.2","provenance":[{"file_id":"1OyMiG7FrcC3ZOUjXu5adfGLEBmmttxSG","timestamp":1550742478507}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"4XivzQv33S6X","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","\n","# Define computational graph\n","X = tf.placeholder(tf.float32, name=\"X\")\n","Y = tf.placeholder(tf.float32, name=\"Y\")\n","\n","addition = tf.add(X, Y, name=\"addition\")\n","\n","\n","# Create the session\n","with tf.Session() as session:\n","\n","    result = session.run(addition, feed_dict={X: [1, 2, 10], Y: [4, 2, 10]})\n","\n","    print(result)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uLXlzQ1k3S6e","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","data=pd.read_csv(\"sample_data/sales_data_training.csv\")\n","data.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8jOxkc4E3S6j","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load training data set from CSV file\n","training_data_df = pd.read_csv(\"sample_data/sales_data_training.csv\", dtype=float)\n","\n","# Pull out columns for X (data to train with) and Y (value to predict)\n","X_training = training_data_df.drop('total_earnings', axis=1).values\n","Y_training = training_data_df[['total_earnings']].values\n","\n","# Load testing data set from CSV file\n","test_data_df = pd.read_csv(\"sample_data/sales_data_test.csv\", dtype=float)\n","\n","# Pull out columns for X (data to train with) and Y (value to predict)\n","X_testing = test_data_df.drop('total_earnings', axis=1).values\n","Y_testing = test_data_df[['total_earnings']].values\n","\n","# All data needs to be scaled to a small range like 0 to 1 for the neural\n","# network to work well. Create scalers for the inputs and outputs.\n","X_scaler = MinMaxScaler(feature_range=(0, 1))\n","Y_scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","# Scale both the training inputs and outputs\n","X_scaled_training = X_scaler.fit_transform(X_training)\n","Y_scaled_training = Y_scaler.fit_transform(Y_training)\n","\n","# It's very important that the training and test data are scaled with the same scaler.\n","X_scaled_testing = X_scaler.transform(X_testing)\n","Y_scaled_testing = Y_scaler.transform(Y_testing)\n","\n","print(X_scaled_testing.shape)\n","print(Y_scaled_testing.shape)\n","\n","print(\"Note: Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0], Y_scaler.min_[0]))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EZeEsekRcFAb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define model parameters\n","learning_rate = 0.001\n","training_epochs = 100\n","\n","# Define how many inputs and outputs are in our neural network\n","number_of_inputs = 9\n","number_of_outputs = 1\n","\n","# Define how many neurons we want in each layer of our neural network\n","layer_1_nodes = 50\n","layer_2_nodes = 100\n","layer_3_nodes = 50"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MxHCM3A1cGt_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Section One: Define the layers of the neural network itself\n","\n","# Input Layer\n","with tf.variable_scope('input'):\n","    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n","\n","# Layer 1\n","with tf.variable_scope('layer_1'):\n","    weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n","    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n","    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n","\n","# Layer 2\n","with tf.variable_scope('layer_2'):\n","    weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n","    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n","    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n","\n","# Layer 3\n","with tf.variable_scope('layer_3'):\n","    weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n","    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n","    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n","\n","# Output Layer\n","with tf.variable_scope('output'):\n","    weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n","    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n","    prediction = tf.matmul(layer_3_output, weights) + biases\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"70espQeacTN6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n","\n","with tf.variable_scope('cost'):\n","    Y = tf.placeholder(tf.float32, shape=(None, 1))\n","    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b6Dru2WHcWMy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Section Three: Define the optimizer function that will be run to optimize the neural network\n","\n","with tf.variable_scope('train'):\n","    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SYJwrk673S6n","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initialize a session so that we can run TensorFlow operations\n","with tf.Session() as session:\n","\n","    # Run the global variable initializer to initialize all variables and layers of the neural network\n","    session.run(tf.global_variables_initializer())\n","\n","    # Run the optimizer over and over to train the network.\n","    # One epoch is one full run through the training data set.\n","    for epoch in range(training_epochs):\n","\n","        # Feed in the training data and do one step of neural network training\n","        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n","\n","        # Print the current training status to the screen\n","        print(\"Training pass: {}\".format(epoch))\n","\n","    # Training is now complete!\n","    print(\"Training is complete!\")\n"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"YCgFMU0q3S6r","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initialize a session so that we can run TensorFlow operations\n","with tf.Session() as session:\n","\n","    # Run the global variable initializer to initialize all variables and layers of the neural network\n","    session.run(tf.global_variables_initializer())\n","\n","    # Run the optimizer over and over to train the network.\n","    # One epoch is one full run through the training data set.\n","    for epoch in range(training_epochs):\n","\n","        # Feed in the training data and do one step of neural network training\n","        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n","\n","        # Every 5 training steps, log our progress\n","        if epoch % 5 == 0:\n","            training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y:Y_scaled_training})\n","            testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y:Y_scaled_testing})\n","\n","            print(epoch, training_cost, testing_cost)\n","\n","    # Training is now complete!\n","    print(\"Training is complete!\")\n","\n","    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n","    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n","\n","    print(\"Final Training cost: {}\".format(final_training_cost))\n","    print(\"Final Testing cost: {}\".format(final_testing_cost))\n"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"B9TlLTRI3S6v","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initialize a session so that we can run TensorFlow operations\n","with tf.Session() as session:\n","\n","    # Run the global variable initializer to initialize all variables and layers of the neural network\n","    session.run(tf.global_variables_initializer())\n","\n","    # Run the optimizer over and over to train the network.\n","    # One epoch is one full run through the training data set.\n","    for epoch in range(training_epochs):\n","\n","        # Feed in the training data and do one step of neural network training\n","        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n","\n","        # Every 5 training steps, log our progress\n","        if epoch % 5 == 0:\n","            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n","            training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n","            testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n","\n","            # Print the current training status to the screen\n","            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n","\n","    # Training is now complete!\n","\n","    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n","    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n","    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n","\n","    print(\"Final Training cost: {}\".format(final_training_cost))\n","    print(\"Final Testing cost: {}\".format(final_testing_cost))\n","\n","    # Now that the neural network is trained, let's use it to make predictions for our test data.\n","    # Pass in the X testing data and run the \"prediciton\" operation\n","    Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n","\n","    # Unscale the data back to it's original units (dollars)\n","    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n","\n","    real_earnings = test_data_df['total_earnings'].values[0]\n","    predicted_earnings = Y_predicted[0][0]\n","\n","    print(\"The actual earnings of Game #1 were ${}\".format(real_earnings))\n","    print(\"Our neural network predicted earnings of ${}\".format(predicted_earnings))\n"],"execution_count":0,"outputs":[]}]}